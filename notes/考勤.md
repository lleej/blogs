# 需求

根据考勤系统导出的打卡记录、异常登记、请假，生成部门异常考勤数据。

## 原始数据

### 打卡记录

文件名称：xxx打卡记录汇总-[日期].xlsx

| 部门名称  | 人员编号 | 姓名 | 日期       | 最早打卡时间         | 最晚打卡时间         |
| --------- | -------- | ---- | ---------- | -------------------- | -------------------- |
| XXX产品线 | 0001     | 张三  | 2019-12-02 | 2019-12-02  08:59:10 | 2019-12-02  18:05:17 |
| XXX产品线 | 0002     | 李四 | 2019-12-03 | 2019-12-03  09:05:38 | 2019-12-03  18:07:04 |
| XXX产品线 | 0003     | 王五  | 2019-12-04 | 2019-12-04  18:02:06 | 2019-12-04  18:02:06 |
| XXX产品线 | 0004     | 赵六  | 2019-12-06 | 2019-12-12  08:38:33 | 2019-12-12  08:38:33 |

分析：

- 只存在有过打卡操作的记录。如：没有2019-12-05的记录
- 上/下班漏打卡，打卡时间均为上/下班时间。如：2019-12-04、2019-12-06
- 有效工作时间为：9:00-18:00，其余时间打卡为迟到/早退。如：2019-12-03迟到

### 考勤异常

文件名称：考勤异常数据_[日期].xls

| 序号 | 工号   | 姓名   | 部门      | 职位       | 异常类型 | 开始日期   | 异常时数 | 异常情况说明/事由  | 流程状态 |
| ---- | ------ | ------ | --------- | ---------- | -------- | ---------- | -------- | ------------------ | -------- |
| 1    | 0001 | 张三 | XXX产品线 | 软件工程师 | 因公外出 | 2019/12/4  | 1        | 业务交流 | 进行中   |
| 2    | 0002 | 李四 | XXX产品线 | 软件工程师 | 其他情况 | 2019/12/5  | 8        | 请假     | 进行中   |
| 3    | 0003 | 王五 | XXX产品线 | 软件工程师 | 培训     | 2019/12/12 | 16       | 外出培训           | 进行中   |
| 4    | 0005 | 马奇 | XXX产品线 | 测试工程师 | 漏打卡   | 2019/12/16 | 8        | 个人原因          | 进行中   |

分析：

- 登记考勤异常（注意：不是正常的请假）
- 异常类型、开始日期、异常时数（注意单位是小时，不是天），异常时数8小时为1天，可能出现跨天的情况
- 异常类型是中文描述，需要在汇总表中体现
- 考勤异常与打卡记录匹配，打卡记录中的漏打卡、迟到/早退等，有可能与考勤异常相关

### 考勤汇总表-请假

文件名称：考勤汇总表-请假.xls

| 序号 | 员工编号 | 员工姓名 | 假别 | 开始日期   | 结束日期   | 缺勤时长 | 开始时间(上午/下午) |
| ---- | -------- | -------- | ---- | ---------- | ---------- | -------- | ------------------- |
| 1    | 0001     | 张三     | 9000 | 2019-12-17 | 2019-12-17 | 1.00     | 上午                |
| 2    | 0002     | 王丽梅   | 9700 | 2019-12-12 | 2019-12-12 | 1.00     | 上午                |
| 3    | 0003     | 王丽梅   | 9800 | 2019-12-03 | 2019-12-03 | 1.00     | 上午                |
| 4    | 0004     | 张庶     | 9910 | 2019-12-10 | 2019-12-10 | 1.00     | 上午                |
| 5    | 0005     | 李博蕊   | 9800 | 2019/12/23 | 2019/12/23 | 1        | 上午                |
| 6    | 0006     | 张苏南   | 9000 | 2019-12-13 | 2019-12-13 | 0.50     | 下午                |

分析：

- 正常的请假数据，需要逐级审批并影响工资
- 员工编号与其他表格中的工号不同，必须使用人名进行匹配
- 假别有专门的对应表
- 缺勤时长，单位是天，支持小数
- 不会出现跨天的情况，跨天的请假会拆分成每天一笔记录
- 开始时间、结束时间和缺勤时长，需要与打卡记录匹配

## 统计结果

文件名称：XXX产品线打卡记录汇总-[日期].xlsx

### 统计详情表(详情页)

| 部门名称  | 人员编号 | 姓名   | 日期       | 上班     | 下班     | 上班 | 下班 | 星期 | 出勤天数 |      | 有异常流程      | 异常/没有记录 |
| --------- | -------- | ------ | ---------- | -------- | -------- | ---- | ---- | ---- | -------- | ---- | --------------- | ------------- |
| XXX产品线 | 0001     | 张云璞 | 2019-12-02 | 08:59:10 | 18:05:17 | 8    | 18   | 1    | 1        |      |                 |               |
| XXX产品线 | 0001     | 张三   | 2019-12-04 | 18:02:06 | 18:02:06 | 18   | 18   | 3    | 3        |      | 12/4漏打卡      |               |
| XXX产品线 | 0001     | 张三   | 2019-12-16 | 09:01:43 | 09:01:43 | 9    | 9    | 1    | 11       |      | 12/16-12/17外出 |               |
| XXX产品线 | 0001     | 张三   | 2019-12-26 | 08:59:47 | 18:06:38 | 8    | 18   | 4    | 16       | OK   |                 | 12/27上班卡   |

分析：

- 以打卡记录表为基础，计算出每笔打卡记录的上班、下班时，累计出勤天数。
- 对上班、下班打卡记录异常的，用红色标注。有异常的在异常流程列填写（日期+类型），没有异常记录的在没有记录列填写（日期+上班卡/下班卡）

### 统计结果(统计页)

| 序号 | 姓名   | 迟到/早退  | 考勤异常（未有打卡记录） | 备注 |
| ---- | ------ | ---------- | ------------------------ | ---- |
| 1    | 李璞   |            |                          |      |
| 2    | 马文学 | 12/10-9:04 |                          |      |
| 3    | 荆蕾   | 12/18-9:03 | 12/3下班卡               |      |
| 4    | 高展   |            | 12/26全天,12/27上班卡    |      |

分析：

- 不关心缺勤时长是否与异常和请假时长匹配

# 实现

## 思路

1. 每个月的考勤日期不相同，并不是严格到月末，最好能指定考勤统计的截止日期
2. 从打卡记录中可以得到本月考勤的人数（如果一个月都没有打卡，可以手动添加统计数据）
3. 时间范围和人员确定后，就可以确定工作日，形成详情表（人员、日期），人数 * 日期数
4. 以人员和日期为主键，合并打卡记录到详情表中
5. 合并异常和请假表
6. 以人员和日期为主键，合并异常表到详情表中
7. 分析每一行记录，如果没有考勤异常，而打卡记录有迟到/早退/漏打情况，则标记到异常列和迟到/早退列
8. 对详情表按人员进行分组，并将迟到/早退和异常信息进行汇总
9. 将详情表和汇总表写入输入的表格文件中
10. 对表格中的列进行样式设置

## 依赖

- pandas
- xlrd
- openpyxl

## Pandas

### 从Excel加载数据


加载的数据，其格式并不一定是我们想要的

1. 列数据类型可能都是`object`，要进行转换
2. 列标签不利于处理（比如说是中文），需要重设标签
3. 需要过滤某些不需要的列和行
4. ...
```python
# pandas.read_excel的强大之处，就在于其考虑到了我们的需求，在读取文件时就可以处理这些情况了
# 注意：converters和dtype不能同时设置同一个列，当同时设置时，只有converters生效
df = pandas.read_excel(filename,
                      sheet_name=1, # 第2个sheet页
                      names=('name', 'date', 'onduty', 'offduty'), # 列的标签
                      usecols=(2, 3, 4, 5), # 需要载入哪些列，从0开始
                      headers=1, # 列头是从第1行开始（第一个行是标题）
                      dtype={'date': 'datetime64', # 进行数据类型转换，是一个字典类型，指定列和类型
                             'onduty': 'datetime64',
                             'offduty': 'datetime64'},
                      converters={'time': lambda x: float(x) * 8, # lambda函数的参数是列的值
                                  'type': lambda x: conf.HOLIDAY_TYPE[str(x)]})
```

### 初始化DataFrame

1. 初始化空的DataFrame

   ```python
   df = pd.DataFrame()
   ```

2. 从数组中初始化

   ```python
   data = np.random.randn(3,3)
   df = pd.DataFrame(data, columns=list('abc'))
   ```

3. 从字典中初始化

   ```python
       names = df['name'].drop_duplicates().tolist()
       days = make_workdays(max_date.year, max_date.month, max_date)
       # 使用字典进行数据初始化，每个key是一个列标签，每个value是数据
       init_data = {'name': sorted(names * len(days)),
                    'date': days * len(names)}
       df = pd.DataFrame(data=init_data)
   ```

### 合并DataFrame

这个小程序中涉及到四个`DataFrame`，分别是：`df_空白`、`df_打卡`、`df_异常`、`df_请假`，每个`DataFrame`进行相应处理后，需要合并成一个`DataFrame`

常用的合并指令有三种`pd.concat`、`pd.merge`和`pd.join`

总的来说：

- `concat`是灵活度最高的，可以根据轴向设置连接
- 其他两种，都是行连接，列是两个`DataFrame`的堆叠

1. 轴向连接

   不是指定某个列进行合并，而是直接将多个对象沿着指定的轴进行堆叠，不管这个轴的索引上多个对象是否有重复值

   - 横轴/行方向。行堆叠（并集）是不变的，列保留哪些是由join参数决定的
   - 纵轴/列方向。列堆叠（并集）是不变的，行保留哪些是由join参数决定的

```python
pd.concat(objs, axis=0, join='outer', join_axes=None, ignore_index=False,
          keys=None, levels=None, names=None, verify_integrity=False,
          copy=True)
# objs 是要合并的DataFrame的序列，如[df1, df2, ...]
# axis 合并的轴 0-行；1-列
# join outer-并集；inner-交集
```

```python
df1
       n1  n2  n3 n4
one     0   1   2  a
two     3   4   5  b
three   6   7   8  c
 
df2
      n1  n5 n4
two    9  10  a
four  11  12  b
six	  13  14  d
# 纵轴连接 / 列堆叠。列不会去重，行以索引连接
df4 = pd.concat([df1, df2], axis=1, keys=['df1', 'df2'], sort=True) 
       df1                  df2           
        n1   n2   n3   n4    n1    n5   n4
four   NaN  NaN  NaN  NaN  11.0  12.0    b
one    0.0  1.0  2.0    a   NaN   NaN  NaN
six    NaN  NaN  NaN  NaN  13.0  14.0    d
three  6.0  7.0  8.0    c   NaN   NaN  NaN
two    3.0  4.0  5.0    b   9.0  10.0    a
 
# 横轴连接 / 行堆叠。列以名称连接去重，行堆叠不以索引连接
df5 = pd.concat([df1,df2], axis=0, keys=['df1', 'df2'])
           n1   n2   n3 n4    n5
df1 one     0  1.0  2.0  a   NaN
    two     3  4.0  5.0  b   NaN
    three   6  7.0  8.0  c   NaN
df2 two     9  NaN  NaN  a  10.0
    four   11  NaN  NaN  b  12.0
    six    13  NaN  NaN  d  14.0

# 横轴连接 + 并集。行进行堆叠，而列进行并集
df6 = pd.concat([df1, df2], axis=0, keys=['df1', 'df2'], join='inner')
           n1 n4
df1 one     0  a
    two     3  b
    three   6  c
df2 two     9  a
    four   11  b
    six    13  d
    
# 纵向连接 + 并集。列进行堆叠，行进行并集
df6 = pd.concat([df1, df2], axis=1, keys=['df1', 'df2'], join='inner')
    df1          df2       
     n1 n2 n3 n4  n1  n5 n4
two   3  4  5  b   9  10  a
```

2. 行连接

   对两个`DataFrame`进行**行连接**，不管参数如何设置，合并后的`DataFrame`的列是参与合并的`DataFrame`的并集

   ```python
   pd.merge(DataFrame1, DataFrame2, how=‘inner’, on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=(’_x’, ‘_y’))
   # 只支持连接两个DataFrame
   # how 设置连接模式 inner outer left right 默认inner
   # on merge的共同列
   # left_on DataFrame1的列
   # right_on DataFrame2的列
   # 如果指定merge的列元素不是唯一的，是多对多的，则以笛卡尔积的形式merge
   ```

   

   ```python
   # 定义两个DataFrame
   df1 = pd.DataFrame({'key': list('bbaca'), 'data1': range(5)})
     key  data1
   0   b      0
   1   b      1
   2   a      2
   3   c      3
   4   a      4
   df2 = pd.DataFrame({'key': list('abd'), 'data2': range(3)})
     key  data2
   0   a      0
   1   b      1
   2   d      2
   # 默认值 注：on='key' how='inner'
   # df1有两个b、两个a，而df2只有1个b、一个a，以笛卡尔积的形式merge 2*1=2
   df3 = pd.merge(df1, df2)
     key  data1  data2
   0   b      0      1
   1   b      1      1
   2   a      2      0
   3   a      4      0
   # 并集连接 how='outer'
   df3 = pd.merge(df1, df2, on='key', how='outer')
     key  data1  data2
   0   b    0.0    1.0
   1   b    1.0    1.0
   2   a    2.0    0.0
   3   a    4.0    0.0
   4   c    3.0    NaN
   5   d    NaN    2.0
   # 如果两边的key名不同，如Key1 key2
   df3 = pd.merge(df1, df2, left_on='key', right_on='key')
   # 左连接，以DataFrame1为全集，DataFrame2匹配，匹配不上的过滤掉
   df3 = pd.merge(df1, df2, on='key', how='left')
     key  data1  data2
   0   b      0    1.0
   1   b      1    1.0
   2   a      2    0.0
   3   c      3    NaN
   4   a      4    0.0
   # 右连接，以DataFrame2为全集，DataFrame1匹配，匹配不上的过滤掉
   df3 = pd.merge(df1, df2, on='key', how='right')
     key  data1  data2
   0   b    0.0      1
   1   b    1.0      1
   2   a    2.0      0
   3   a    4.0      0
   4   d    NaN      2
   ```

3. 索引连接

   如果是直接根据索引进行合并的话，`DataFrame`有一个直接的`join()`方法

   - 列堆叠

   ```python
   DataFrame.join(other,on=None,how='left',lsuffix='',rsuffix='',sort=False)
   ```

   ```python
   df1
          n1  n2  n3 n4
   one     0   1   2  a
   two     3   4   5  b
   three   6   7   8  c
    
   df2
         n1  n5 n4
   two    9  10  a
   four  11  12  b
   six	  13  14  d
   # 默认how='left'左连接。注意：列如果有重叠，必须设置lsuffix和rsuffix，否则会报错
   df1.join(df2,lsuffix='_x',rsuffix='_y')
          n1_x  n2  n3 n4_x  n1_y    n5 n4_y
   one       0   1   2    a   NaN   NaN  NaN
   two       3   4   5    b   9.0  10.0    a
   three     6   7   8    c   NaN   NaN  NaN
   # 右连接
   df1.join(df2,lsuffix='_x',rsuffix='_y', how='right')
         n1_x   n2   n3 n4_x  n1_y  n5 n4_y
   two    3.0  4.0  5.0    b     9  10    a
   four   NaN  NaN  NaN  NaN    11  12    b
   six    NaN  NaN  NaN  NaN    13  14    d
   # 外连接（并集）
          n1_x   n2   n3 n4_x  n1_y    n5 n4_y
   four    NaN  NaN  NaN  NaN  11.0  12.0    b
   one     0.0  1.0  2.0    a   NaN   NaN  NaN
   six     NaN  NaN  NaN  NaN  13.0  14.0    d
   three   6.0  7.0  8.0    c   NaN   NaN  NaN
   two     3.0  4.0  5.0    b   9.0  10.0    a
   # 内连接（交集）
        n1_x  n2  n3 n4_x  n1_y  n5 n4_y
   two     3   4   5    b     9  10    a
   ```

### 逐行处理(Apply)

对于考勤异常的认定，规则比较繁琐，需要将打卡信息、异常信息、请假信息都合并后才能处理

- 考勤异常，含迟到/早退，缺勤
- 没有异常登记
- 没有请假记录

对于符合上述条件的行，需要额外备注异常明细

- 迟到/早退的，记录mm/dd-hh:mm
- 缺勤的，记录mm/dd 上午/下午/全天

因为需要对`DataFrame`中的每一行进行处理，类似于`map`操作，可以使用`apply()`方法

```python
DataFrame.apply(func,axis=0,broadcast=None,raw=False,reduce=None,result_type=None,args=(),** kwds)
# axis=0,1... 沿哪个轴方向应用。注意：这个是反的。0-行，作用与每一列，1-列，作用于每一行

```

```python
pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])
   A  B
0  4  9
1  4  9
2  4  9
# axis=0|行，作用于每一列
df.apply(np.sqrt)
     A    B
0  2.0  3.0
1  2.0  3.0
2  2.0  3.0
# 作用于列
df.apply(np.sum, axis=0)
A    12
B    27
# 作用于行
df.apply(np.sum, axis=1)
0    13
1    13
2    13
```

### 分组统计

当考勤信息全部处理完成后，`DataFrame`有(人数 * 工作日数)行，最终需要按人数进行分组统计，合并为人数的集合

```python
DataFrame.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, observed=False, **kwargs)

group.apply(func,axis=0,broadcast=None,raw=False,reduce=None,result_type=None,args=(),** kwds)
# 分组的apply，根据返回值决定是map还是reduce。如果返回一个DataFrame就是map，如果返回一个Series就是reduce
# 分组中的apply，传入的是一个分组的所有DataFrame
```

```python
    def _general_stat(df: pd.DataFrame) -> pd.Series:
        stat1, stat2 = [], []
        for i in range(len(df)):
            if df.iloc[i]['chidao'] not in (np.NaN, None):
                stat1.append(df.iloc[i]['chidao'])
            if df.iloc[i]['abn'] not in (np.NaN, None):
                stat2.append(df.iloc[i]['abn'])
        # 返回的是Series，所以是reduce操作
        return pd.Series({'chidao': '\n'.join(stat1), 'abn': ';'.join(stat2)})

    df1 = pd.DataFrame({'name': df_data['name'], 'chidao': df_data['chidao'], 'abn': df_data['abn']})
    df1 = df_group.groupby('name').apply(_general_stat)

```

















