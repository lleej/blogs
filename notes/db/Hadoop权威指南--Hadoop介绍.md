# 分布式存储和计算

## 数据

数据量呈爆炸式增长，对数据的存储和分析都带来了性能挑战。对于TB级或更高数量级的大数据，硬盘的吞吐量是数据处理的瓶颈。业界也采用了一些高性能计算（HPC）的架构，将算力分散到集群中的各个节点中，但数据还是集中存储在（SAN）中为各个节点提供数据共享，导致网络带宽成为新的瓶颈。

互联网和物联网产生大量的半结构化、非结构化数据（图片、网页、视频等），这些数据占用空间更大，对数据的处理需求更广泛，传统的数据库无法高效率的存储和管理这些数据，需要新的存储体系支持

Google将其使用的GFS和MapReduce技术通过论文形式开放出来，给业界解决大数据的存储和计算提供了理论支撑。

## 分布式

GFS和HDFS都是采用分布式存储来解决大数据的存储管理，分布式存储的意义在于：可以将算力向存储靠近，将算力分配给存储节点进行处理（存储不占用CPU和内存资源），一方面合理的利用了资源，而且解决了需要大量网络传输数据的传统分布式计算的问题，实现了**数据本地化**这一核心特性。

MapReduce将任务划分成Map和Reduce，分配给集群内的各个节点，并由资源管理节点对任务的运行状态进行调度和管理。这些节点之前采用**无共享框架**，各个任务之间彼此独立，解决了任务失效导致的整个计算失效的问题。

Hadoop中的处理模型是支持线性伸缩的。对数据分区后，Map和Reduce可以在各个分区并行工作。当数据量增加时，可以采用横向扩展（增加集群中节点数量）的方式，保证运行速度，而这是关系型数据库所不具备的

# Hadoop的由来

Hadoop是Apache Lucene的创始人道格卡丁（Daug Cutting）创建的，Lucene是一个应用广泛的文本搜索系统库。

Hadoop的前身Apache Nutch是Lucene项目的一部分，它借鉴了Google的GFS和MapReduce的论文。

2006年2月，Nutch项目从Lucene中移出，称为一个Apache顶级项目，命名为Hadoop。

同年，创始人加入雅虎并将Hadoop用于雅虎的搜索引擎。

2014年GraySort基准排序大赛中，Databricks公司的团队使用207个节点的Spark集群对100TB数据进行排序，用时1406秒，每分钟4.27TB，相当于14秒处理1TB数据

# 商业支持

- Cloudera
- Hortonworks
- MapR

提供商业化的Hadoop支持

