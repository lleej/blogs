# 简介

MapReduce是一种可用于数据处理的**编程模型**，支持多种语言开发，如：Java、Ruby、Python等。MapReduce是并行运行的，可以将大规模的数据分析任务分发给集群中的多个节点。

MapReduce的优势在于：处理大规模数据集

书中的案例是计算气象日志文件中每一年的最高气温

# 数据集

## 预处理

Hadoop适合处理少量大型文件，而不是大量小型文件。当待处理的数据是小型文件时，需要进行预处理，将文件合并为大文件。具体办法有：

- 从源头合并成大型文件
- 对小文件进行打包，如archive

## 格式

MapReduce默认支持文本数据格式

## 案例

书中的案例是将每一年中的多个小文件，合并为一个以年份命名的数据集。

书中是采用`bzip2`将文件打包成一个文件，例如：1901.tar.bz2

# MapReduce处理

处理过程分成两个阶段，分别是：Map和Reduce。

每个阶段都以键值对作为输入和输出，类型由开发人员确定，需要有两个处理函数：Map和Reduce，多种语言均可

## Map阶段

对于文本格式的数据集（书中是气象日志），Map阶段将数据集的每一行作为输入，键：行起始位置的偏移量，值：日志中的行文本。**猜测这应该是Map内置的文本处理类提供的功能**

也可以理解为Map阶段是做数据的准备工作，例如：从输入中将提取需要处理的数据，并组合成Reduce阶段需要的格式

本例中，Map函数对每个键值对的值进行处理，提取出年份和温度，输出到键值对中，键：年份，值：温度值。

Map会基于键对键值对进行排序和分组，便于Reduce阶段的处理。

输出结果存储在本地磁盘中，而不是HDFS中，是因为给结果是中间结果，当Reduce阶段处理完成后会被丢弃，放在HDFS中显得小题大做。

如果某个节点的Map任务失效/节点失效，则会在另外的节点上重新运行Map任务，之前的处理中间结果被丢弃。

```shell
# 数据集中的内容
0067011990999991950051507004...9999999N9+00001+9999999999...
0043011990999991950051512004...9999999N9+00221+9999999999...
0043011990999991950051518004...9999999N9-00111+9999999999...
0043011990999991949032412004...9999999N9+01111+9999999999...
...

# 作为键值对输入到Map函数
(0, 0067011990999991950051507004...9999999N9+00001+9999999999...)
(106, 0043011990999991950051512004...9999999N9+00221+9999999999...)
(212, 0043011990999991950051518004...9999999N9-00111+9999999999...)
(318, 0043011990999991949032412004...9999999N9+01111+9999999999...)
...

# Map函数提取出年份和温度数据
(1950, 0)
(1950, 22)
(1950, 11)
(1949, 111)

# Map函数输出的键值对，经过了排序和分组
(1949, [111])
(1950, [0, 22, -11])
```

## Reduce阶段

从HDFS中读取Map阶段准备用于计算的数据，进行最终的计算，并将结果存储在HDFS中。

# 调度

对于较大的数据集，仅靠单个节点处理是无法满足时间需求的，这就需要调度系统（YARN）将MapReduce任务分配给集群中的多个节点，并行完成。

1. 将输入的数据集进行分片，为每个片构建一个独立的Map任务，处理分片中的数据。并行处理每个分片，可以获得更好的负载均衡。分片的数量直接关系到性能，分片多则执行成本低、但管理成本和构建任务成本高，因此分片的大小必须是一个综合成本最优的值，默认为HDFS的分块大小（128M）
2. 将运算任务分配给存储输入数据的节点上（HDFS分块存储），可以获得最佳性能，这就是“数据本地化优化”。如果存储数据的节点没有空闲，则分配给一个机架内的其它节点，再次分配给其它节点，但都会造成网络传输。
3. reduce任务不具备数据本地化优势，单个reduce任务的输入来自于所有mapper的输出，这个过程必须进行网络传输。
4. 当存在多个reduce任务时，map和reduce之间会加入shuffle(混洗)步骤，为什么呢？
5. 当没有reduce任务时，map任务将结果写入HDFS中

## combiner函数

集群中可用带宽限制了MapReduce作业的数量，因此应该尽量压缩在Map和reduce任务间的数据传输，这时就可以使用combiner函数。

combiner函数与reduce函数的功能是一致的，因此有些reduce任务是不能使用combiner的。比如：求最大值、求和等适用，但求平均数就不适用。

combiner使用的前提是存在多个map任务。

combiner的作用是在map输出后，在本地先进行reduce运算，将得出的结果再传输给reduce任务节点，这样就可以大大减少map和reduce间的数据传输量

```shell
# 使用combiner前
# map1
(1950, 0)
(1950, 20)
(1950, 10)
# map2
(1950, 25)
(1950, 15)
# reduce处理的数据
(1950, [0, 20, 10, 25, 15])

# 使用combiner后
# reduce处理的数据
(1950, [20, 25])
```

### 问题

combiner函数时Java提供的，还是hadoop框架提供的

# 开发

## API

Hadoop提供了MapReduce的API，允许使用非Java的其他语言编写map和reduce函数

## Streaming

使用标准流作为Hadoop和应用程序间的接口，使用任何编程语言通过标准输入/输出写MR程序

## 区别

API中的map函数每次只能处理一条记录，streaming却可以同时处理若干行，取决于读操作

